{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdVB8gdufnIk"
      },
      "source": [
        "# Todo\n",
        "0. 현재 attempt 1-1 진행중 오류는 주석 참고바람\n",
        "1. searchframe 구분해서 추가처리하기\n",
        "2. searchframe의 경우 맨 위의 장소를 클릭하도록 설정\n",
        "3. 각 리뷰가 없는 경우 빠르게 넘겨서 시간절약하기\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6o7sktkfsJmH"
      },
      "source": [
        "#selenium settings\n",
        "- 참고\n",
        "https://velog.io/@kimdy0915/Selenium%EC%9C%BC%EB%A1%9C-%EB%84%A4%EC%9D%B4%EB%B2%84-%EC%A7%80%EB%8F%84-%ED%81%AC%EB%A1%A4%EB%A7%81%ED%95%98%EA%B8%B0\n",
        "\n",
        "https://eastsea92-com.tistory.com/80\n",
        "\n",
        "https://jinooh.tistory.com/89\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yaq6VCvTuII_",
        "outputId": "b5797f9d-dcec-413a-a400-69e5798e78a9"
      },
      "outputs": [],
      "source": [
        "!pip install selenium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "klP80wzayETr"
      },
      "outputs": [],
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "import json\n",
        "import time\n",
        "from time import sleep\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrkgzG6mym0G"
      },
      "source": [
        "load chrome driver"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'.'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "os.curdir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1sOC9q1x7lG"
      },
      "source": [
        "# 절차\n",
        "\n",
        "1. 가게에 대한 unique를 list에 넣기\n",
        "2. for 문을 돌면서 해당 가게에 대한 정보\n",
        "    - 홈 - datalab 키워드\n",
        "    - 사진 - 이미지\n",
        "    - 리뷰 - 메뉴/특징\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0icws1HtzcW"
      },
      "outputs": [],
      "source": [
        "# # 검색할 키워드\n",
        "# ## 검색할 키워드를 입력받은 후 for문장으로 해당 가게에 대한 정보 가져오기\n",
        "# shinhan_store = ['','','','']\n",
        "\n",
        "# datalab = []\n",
        "# picture = []\n",
        "# review = []\n",
        "\n",
        "# driver = webdriver.Chrome('./chromedriver')\n",
        "# driver.get('https://map.naver.com/v5/search')\n",
        "\n",
        "# for store in shinhan_store:\n",
        "\n",
        "#     # 10 secs wait until find css\n",
        "#     time_wait(10, 'div.input_box > input.input_search')\n",
        "\n",
        "#     # 검색창 찾기\n",
        "#     search = driver.find_element(By.CSS_SELECTOR, 'div.input_box > input.input_search')\n",
        "#     search.clear()\n",
        "#     search.send_keys(store)\n",
        "#     search.send_keys(Keys.ENTER)\n",
        "\n",
        "#     sleep(1)\n",
        "\n",
        "#     switch_method('searchIframe')\n",
        "#     page_down(20)\n",
        "#     sleep(3)\n",
        "\n",
        "#     # 홈\n",
        "#     ## datalab의 키워드\n",
        "#     path = '/html/body/div[3]/div/div/div/div[6]/div/div[9]'\n",
        "#     ### theme-keyword\n",
        "#     /html/body/div[3]/div/div/div/div[6]/div/div[9]/div[1]/div[1]/div/ul/li[1]/span[1]\n",
        "#     /html/body/div[3]/div/div/div/div[6]/div/div[9]/div[1]/div[1]/div/ul/li[2]/span[1]\n",
        "#     /html/body/div[3]/div/div/div/div[6]/div/div[9]/div[1]/div[1]/div/ul/li[3]/span[1]\n",
        "#     ### 내용1\n",
        "#     /html/body/div[3]/div/div/div/div[6]/div/div[9]/div[1]/div[1]/div/ul/li[1]/span[2]/span[1]\n",
        "#     /html/body/div[3]/div/div/div/div[6]/div/div[9]/div[1]/div[1]/div/ul/li[1]/span[2]/span[5]\n",
        "#     ### 내용2\n",
        "#     /html/body/div[3]/div/div/div/div[6]/div/div[9]/div[1]/div[1]/div/ul/li[2]/span[2]/span[1]\n",
        "#     /html/body/div[3]/div/div/div/div[6]/div/div[9]/div[1]/div[1]/div/ul/li[2]/span[2]/span[5]\n",
        "#     ### 내용3\n",
        "#     /html/body/div[3]/div/div/div/div[6]/div/div[9]/div[1]/div[1]/div/ul/li[2]/span[3]/span[1]\n",
        "#     /html/body/div[3]/div/div/div/div[6]/div/div[9]/div[1]/div[1]/div/ul/li[2]/span[3]/span[5]\n",
        "\n",
        "#     # 리뷰\n",
        "#     to_click1 = /html/body/div[3]/div/div/div/div[4]/div/div/div/div/a[4]/span\n",
        "#     # 메뉴박스\n",
        "#     review = /html/body/div[3]/div/div/div/div[6]/div[3]/div[3]\n",
        "#     menu_box = /html/body/div[3]/div/div/div/div[6]/div[3]/div[3]/div[1]/div[1]/div/div[1]\n",
        "#     menu = /html/body/div[3]/div/div/div/div[6]/div[3]/div[3]/div[1]/div[1]/div/div[1]/div/div/div/div/span[2]/a/span[1]\n",
        "#     # 특징박스\n",
        "#     feature = /html/body/div[3]/div/div/div/div[6]/div[3]/div[3]/div[1]/div[1]/div/div[2]\n",
        "#     feqture_1 = /html/body/div[3]/div/div/div/div[6]/div[3]/div[3]/div[1]/div[1]/div/div[2]/div/div/div/div/span[2]/a/span[1]\n",
        "\n",
        "#     # 사진\n",
        "#     to_click2 = /html/body/div[3]/div/div/div/div[4]/div/div/div/div/a[5]/span\n",
        "#     # 동영상이 아니라 사진의 경우만\n",
        "#     # 대략 5~10개 이미지 url 저장\n",
        "\n",
        "#     picture_box = /html/body/div[3]/div/div/div/div[6]/div[5]/div/div/div/div[1]/a\n",
        "#     url = /html/body/div[3]/div/div/div/div[6]/div[5]/div/div/div/div[1]/a/div/div[1]/img\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<>:1: SyntaxWarning: invalid escape sequence '\\g'\n",
            "<>:1: SyntaxWarning: invalid escape sequence '\\g'\n",
            "C:\\Users\\tldbs\\AppData\\Local\\Temp\\ipykernel_6112\\3173642064.py:1: SyntaxWarning: invalid escape sequence '\\g'\n",
            "  concat = pd.read_csv('C:\\github\\shinhan_merge.csv', encoding='utf-8')\n"
          ]
        }
      ],
      "source": [
        "concat = pd.read_csv('C:\\github\\shinhan_merge.csv', encoding='utf-8')\n",
        "concat\n",
        "\n",
        "search_cols = concat['MCT_NM']\n",
        "search_cols = search_cols.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "수정해야할 부분\n",
        "- search cols에서 (사) (주) (유) 등이 있는데ㅐ 그러면 검색이 안됨. 따라서 처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['한국수상레저안전협회 제주제주시지부',\n",
              " '아웃백스테이크하우스 제주아일랜드점',\n",
              " '케이디에셋 담앤루',\n",
              " ' 베이힐',\n",
              " ' 비케이알 버거킹 제주화북DT점',\n",
              " ' 성우디엔에프',\n",
              " ' 신세계푸드 제주신화월드  고래라면',\n",
              " ' 신세계푸드 제주신화월드  윤경양식당',\n",
              " ' 신세계푸드 제주신화월드  티플레이스',\n",
              " ' 신세계푸드 제주신화월드  화니제주신',\n",
              " ' 아워홈 제주대학교병원제주점',\n",
              " ' 아워홈 제주지방합동청사점',\n",
              " ' 아워홈 제주한라병원점',\n",
              " ' 현대그린푸드 국세공무원교육원(제주)',\n",
              " '구푸디엉또정',\n",
              " '그라스랜드',\n",
              " '그랜드부민',\n",
              " '네츄럴파크리조트',\n",
              " '다모아미래컨벤션센터',\n",
              " '리앤이라마띠네제주호텔브릿지서귀포점',\n",
              " '모던돔베제주노형본점',\n",
              " '바다바라',\n",
              " '별돈별',\n",
              " '블루밍그릴',\n",
              " '비케이알 버거킹 제주노형점',\n",
              " '산굼부리',\n",
              " '삼다도횟집',\n",
              " '새들러컴퍼니 제주지점',\n",
              " '서민당',\n",
              " '서울인더스트리포트그릴스테이크하우스']"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "search_cols_1 = search_cols[:30]\n",
        "search_cols_2 = list(map(lambda x : x[3:] if len(x) > 3 else x, search_cols_1))\n",
        "search_cols_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error while clicking first search result for 1080칼국수: Unable to locate list container.\n"
          ]
        }
      ],
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
        "import time\n",
        "import pandas as pd\n",
        "from selenium.webdriver import ActionChains\n",
        "\n",
        "\n",
        "# Define the list of stores to be scraped\n",
        "stores = search_cols_2\n",
        "stores = ['1080칼국수','협재해녀의집','해송갈치 제주성산일출봉점','통큰돼지']\n",
        "# Initialize webdriver options and webdriver\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument(\"--start-maximized\")\n",
        "driver = webdriver.Chrome(options=options)\n",
        "\n",
        "action = ActionChains(driver)\n",
        "fail_to_crawling = []\n",
        "\n",
        "\n",
        "###################### 검색 키워드를 바탕으로 시작\n",
        "results = []\n",
        "for store in stores:\n",
        "    ######################### 기본세팅\n",
        "    # URL 입력\n",
        "    keyword = store\n",
        "    url = f'https://map.naver.com/p/search/{keyword}'\n",
        "    driver.get(url)\n",
        "\n",
        "    # 페이지 로드 \n",
        "    try:\n",
        "        WebDriverWait(driver, 3).until(\n",
        "            lambda d: d.execute_script('return document.readyState') == 'complete'\n",
        "        )\n",
        "    except TimeoutException:\n",
        "        print(f\"타임아웃 for {store}!\")\n",
        "        continue\n",
        "\n",
        "    ################ searchIframe 및 entryIframe에 따른 처리\n",
        "    # 1. searchIframe일 경우 첫번째 가게 클릭하기\n",
        "    try:\n",
        "        search_iframe = WebDriverWait(driver, 4).until(\n",
        "            EC.presence_of_element_located((By.XPATH, '//*[@id=\"searchIframe\"]'))\n",
        "        )\n",
        "        driver.switch_to.frame(search_iframe)\n",
        "        \n",
        "        # Explicitly wait for the list container to load\n",
        "        try:\n",
        "            list_scroll_container = WebDriverWait(driver, 2).until(\n",
        "            EC.presence_of_element_located((By.XPATH, '//*[@id=\"app-root\"]/div[@class=\"mFg6p\"]/div[@class=\"XUrfU\"]/div[@class=\"Ryr1F\"]'))\n",
        "        )\n",
        "            # 첫번째 가게항목\n",
        "            # /ul/li[@class=\"VLTHu OW9LQ\"]/div[@class=\"qbGlu\"]/div[2]/a/div[@class=\"ApCpt\"]/div[@class=\"place_bluelink C6RjW\"]\n",
        "            try : \n",
        "                first_result = list_scroll_container.find_element(By.XPATH, './ul/li[1]')\n",
        "                # print(f\"first_result : {first_result.get_attribute('innerHTML')}\")\n",
        "            except : \n",
        "                first_result = list_scroll_container.find_element(By.CLASS_NAME, '/ul/li[@class=\"VLTHu OW9LQ\"]')\n",
        "                # print(f\"except first_result : {first_result.get_attribute('innerHTML')}\")\n",
        "\n",
        "            # Try clicking using XPath first\n",
        "            try:\n",
        "                link_button = first_result.find_element(By.XPATH, './div[1]/div[2]/a[1]/div/div/span')\n",
        "                # action chain을 이용해서 강제로 클릭하도록 설정\n",
        "                action.move_to_element(link_button).click().perform()\n",
        "                # print(f\"link_button : {link_button.get_attribute('innerHTML')}\")\n",
        "                # driver.execute_script(\"arguments[0].click();\", link_button)\n",
        "                ###### 디버깅파트\n",
        "                # print(f\"됐냐?\")\n",
        "                # current_url = driver.current_url\n",
        "                # print(f\"클릭 후 URL: {current_url}\")\n",
        "                # current_title = driver.title\n",
        "                # print(f\"클릭 후 페이지 타이틀: {current_title}\")\n",
        "                time.sleep(2)  # Wait for page transition\n",
        "            except NoSuchElementException: \n",
        "                print(f\"링크버튼 어디감? xpath 대신 클래스 이름으로 시도\")\n",
        "                try:\n",
        "                    # Fallback to class name\n",
        "                    link_button = first_result.find_element(By.CLASS_NAME, 'place_bluelink')\n",
        "                    action.move_to_element(link_button).click().perform()\n",
        "                    time.sleep(3)  # Wait for page transition\n",
        "                except NoSuchElementException:\n",
        "                    print(f\"링크버튼 어디감?\")\n",
        "                    continue\n",
        "        except TimeoutException:\n",
        "            print(f\"Error while clicking first search result for {store}: Unable to locate list container.\")\n",
        "            continue\n",
        "    except TimeoutException:\n",
        "        print(f\"Search iframe not found for {store}, attempting entry iframe.\")\n",
        "        continue\n",
        "\n",
        "    # 2. entryIframe일 경우 밑의 코드 진행 \n",
        "\n",
        "    # iframe 세팅\n",
        "    attempts = 0\n",
        "    max_attempts = 3\n",
        "    while attempts < max_attempts:\n",
        "        try:\n",
        "            driver.switch_to.default_content()\n",
        "            iframe = WebDriverWait(driver, 5).until(\n",
        "                EC.presence_of_element_located((By.XPATH, '//*[@id=\"entryIframe\"]'))\n",
        "            )\n",
        "            print(f\"entryIframe 로드.\")\n",
        "            driver.switch_to.frame(iframe)\n",
        "            break\n",
        "        except TimeoutException:\n",
        "            attempts += 1\n",
        "            time.sleep(1)  \n",
        "            if attempts == max_attempts:\n",
        "                print(f\"Failed to load iframe after multiple attempts for {store}.\")\n",
        "                # 크롤링 실패한 부분은 리스트에 저장해서 다시 돌릴 수 있도록 지정\n",
        "                print(f\"crawling fatil : {store} to fail_to_crawling\")\n",
        "                fail_to_crawling.append(store)\n",
        "                continue\n",
        "\n",
        "    # 로딩을 위해 스크롤링 진행\n",
        "    SCROLL_PAUSE_TIME = 2\n",
        "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
        "    while True:\n",
        "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "        time.sleep(SCROLL_PAUSE_TIME)\n",
        "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
        "        if new_height == last_height:\n",
        "            break\n",
        "        last_height = new_height\n",
        "    time.sleep(1)\n",
        "\n",
        "    ###################### datalab 크롤링\n",
        "    try:\n",
        "        app_root = driver.find_element(By.XPATH, '//*[@id=\"app-root\"]')\n",
        "        main_div = app_root.find_element(By.XPATH, './div/div/div[@role=\"main\"]')\n",
        "        target_div = main_div.find_element(By.XPATH, './div[contains(@style, \"min-height\")]')\n",
        "        datalab_section = target_div.find_element(By.XPATH, './div/div[9]')\n",
        "        theme_keywords = datalab_section.find_element(By.CLASS_NAME, 'place_section_content')\n",
        "\n",
        "        atmosphere_elements = theme_keywords.find_elements(By.XPATH, \".//ul/li[span[contains(text(), '분위기')]]/span[@class='sJgQj']/span\")\n",
        "        popular_elements = theme_keywords.find_elements(By.XPATH, \".//ul/li[span[contains(text(), '인기토픽')]]/span[@class='sJgQj']/span\")\n",
        "        purpose_elements = theme_keywords.find_elements(By.XPATH, \".//ul/li[span[contains(text(), '찾는목적')]]/span[@class='sJgQj']/span\")\n",
        "\n",
        "        atmosphere = [elem.text for elem in atmosphere_elements]\n",
        "        popular_topics = [elem.text for elem in popular_elements]\n",
        "        purpose = [elem.text for elem in purpose_elements]\n",
        "\n",
        "        result = {\n",
        "            \"가게\": store,\n",
        "            \"테마_분위기\": atmosphere,\n",
        "            \"테마_인기토픽\": popular_topics,\n",
        "            \"테마_찾는목적\": purpose\n",
        "        }\n",
        "        results.append(result)\n",
        "    except Exception as e:\n",
        "        print(f\"Error while extracting datalab information for {store}:\", e)\n",
        "    \n",
        "    time.sleep(2)\n",
        "\n",
        "\n",
        "\n",
        "    ############################## 리뷰로 넘어가서 진행하기\n",
        "    try:\n",
        "        # 리뷰버튼 클릭\n",
        "        for k in range(1, 6) : \n",
        "            try: \n",
        "                tab_button = driver.find_element(By.XPATH, f'//*[@id=\"app-root\"]/div/div/div/div[4]/div/div/div/div/a[{k}]')\n",
        "                span_text = tab_button.find_element(By.XPATH, './span').text\n",
        "                if span_text == '리뷰':\n",
        "                    review_button = tab_button\n",
        "                    break \n",
        "            except Exception as e:\n",
        "                continue \n",
        "        if review_button: \n",
        "            review_button.click() \n",
        "            # 리뷰 탭 로딩 확인\n",
        "            try:\n",
        "                WebDriverWait(driver, 5).until(\n",
        "                    EC.presence_of_element_located((By.XPATH, '//*[@id=\"app-root\"]/div/div/div/div[6]'))\n",
        "                )\n",
        "                print(f\"{store}: 리뷰 페이지 로드 성공\")\n",
        "            except TimeoutException:\n",
        "                print(f\"{store}: 리뷰 페이지 로드 실패, 사진 수집으로 넘어가지 않음\")\n",
        "                continue\n",
        "\n",
        "        # iframe 로딩을 위해 스크롤링 진행\n",
        "        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
        "        while True:\n",
        "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "            time.sleep(SCROLL_PAUSE_TIME)\n",
        "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
        "            if new_height == last_height:\n",
        "                break\n",
        "            last_height = new_height\n",
        "        time.sleep(2)\n",
        "\n",
        "        # 리뷰 정보를 수집할 준비\n",
        "        \n",
        "        ############################## 리뷰 정보 수집\n",
        "        try:\n",
        "            review_box = driver.find_element(By.XPATH, '//*[@id=\"app-root\"]/div/div/div/div[6]/div[3]/div[3]/div[1]')\n",
        "        except:\n",
        "            review_box = driver.find_element(By.CLASS_NAME, 'place_section_content')\n",
        "\n",
        "        try:\n",
        "            tag_filters = review_box.find_element(By.XPATH, '//*[@id=\"_tag_filters\"]/div/div')\n",
        "        except:\n",
        "            tag_filters = review_box.find_element(By.CLASS_NAME, 'mWnvl')\n",
        "\n",
        "        menu_features = {}\n",
        "        feature_items = {}\n",
        "        for n in range(1, 3):\n",
        "            try:\n",
        "                div_element = tag_filters.find_element(By.XPATH, f'//*[@id=\"_tag_filters\"]/div/div[{n}]')\n",
        "            except:\n",
        "                div_element = tag_filters.find_element(By.XPATH, f'.//div[{n}]')\n",
        "\n",
        "            if n == 1:\n",
        "                div_class = \"JWiV0 eZMAS xcTvu\"  # 메뉴\n",
        "            elif n == 2:\n",
        "                div_class = \"JWiV0 khWUF eZMAS xcTvu\"  # 특징\n",
        "\n",
        "            try:\n",
        "                menu_items = div_element.find_elements(By.XPATH, './/a')\n",
        "                for item in menu_items:\n",
        "                    span_1 = item.find_element(By.XPATH, './span[1]').text\n",
        "                    span_2 = item.find_element(By.XPATH, './span[2]').text\n",
        "                    if n == 1:\n",
        "                        menu_features[span_1] = span_2\n",
        "                    elif n == 2:\n",
        "                        feature_items[span_1] = span_2\n",
        "            except Exception as e:\n",
        "                print(f\"Error while extracting menu/features for {store}, div {n}:\", e)\n",
        "\n",
        "        # Add the menu and features data to the result\n",
        "        result[\"메뉴\"] = menu_features\n",
        "        result[\"특징\"] = feature_items\n",
        "    except Exception as e:\n",
        "        print(f\"Error while navigating to reviews for {store}:\", e)\n",
        "    \n",
        "    time.sleep(1)\n",
        "    \n",
        "    ############################## 사진으로 넘어가서 진행하기\n",
        "    try:\n",
        "        # 사진 버튼 클릭\n",
        "        photo_button = None\n",
        "        for k in range(1, 6):\n",
        "            try:\n",
        "                tab_button = driver.find_element(By.XPATH, f'//*[@id=\"app-root\"]/div/div/div/div[4]/div/div/div/div/a[{k}]')\n",
        "                span_text = tab_button.find_element(By.XPATH, './span').text\n",
        "                if span_text == '사진':\n",
        "                    photo_button = tab_button\n",
        "                    break\n",
        "            except Exception as e:\n",
        "                continue\n",
        "\n",
        "        if photo_button:\n",
        "            photo_button.click()\n",
        "        else:\n",
        "            print(f\" 사진 버튼 없음 : {store}.\")\n",
        "            continue\n",
        "        \n",
        "        # 스크롤 세 번 진행\n",
        "        for _ in range(3):\n",
        "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "        time.sleep(1)\n",
        "        \n",
        "        # 사진 정보 수집\n",
        "        pic_tmp = []\n",
        "        try:\n",
        "            app_root = driver.find_element(By.XPATH, '//*[@id=\"app-root\"]')\n",
        "            main_div = app_root.find_element(By.XPATH, './div/div')\n",
        "            role_main_div = main_div.find_element(By.XPATH, './div[@role=\"main\"]')\n",
        "            target_div = role_main_div.find_element(By.XPATH, './div[contains(@style, \"min-height\")]')\n",
        "        except Exception as e:\n",
        "            print(f\"위치 못찾음 : {store}:\", e)\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            photo_section = target_div.find_element(By.XPATH, './div[contains(@class, \"place_section\")]')\n",
        "            # print(f'photo_section found: {photo_section}')\n",
        "        except:\n",
        "            try:\n",
        "                photo_section = target_div.find_element(By.CLASS_NAME, 'place_section no_margin')\n",
        "                # print(f'photo_section (alternative) found: {photo_section}')\n",
        "            except Exception as e:\n",
        "                print(f\"photo section 못찾음 {store}: {e}\")\n",
        "                continue\n",
        "        try:\n",
        "            photo_content = WebDriverWait(driver, 1).until(\n",
        "                EC.presence_of_element_located((By.CLASS_NAME, 'place_section_content'))\n",
        "            )\n",
        "            # print(f'photo_content found: {photo_content}')\n",
        "        except Exception as e:\n",
        "            print(f'photo_content 못찾음 {store}: {e}')\n",
        "            continue\n",
        "\n",
        "        # print(f\"photo_content : {photo_content}\")\n",
        "        for n in range(1, 11):\n",
        "            try:\n",
        "                photo_div = photo_content.find_element(By.XPATH, f'./div/div/div[{n}]/a')\n",
        "                img_element = photo_div.find_element(By.XPATH, './img')\n",
        "                img_src = img_element.get_attribute('src')\n",
        "                pic_tmp.append(img_src)\n",
        "            except Exception as e:\n",
        "                print(f\"이미지 추출 오류 {n} for {store}: {e}\")\n",
        "\n",
        "        result[\"사진\"] = pic_tmp\n",
        "    except Exception as e:\n",
        "        print(f\"Error while navigating to photos for {store}:\", e)\n",
        "\n",
        "    # Append the result for each store\n",
        "    results.append(result)\n",
        "\n",
        "################ Close the browser\n",
        "# driver.quit()\n",
        "\n",
        "################### 크롤링 최종결과를 df에 저장\n",
        "df = pd.DataFrame(results)\n",
        "################## 원본데이터에 입력\n",
        "# df = pd.merge(df, shinhan, on='가게명', how='outer')\n",
        "################### 통합된 데이터 저장\n",
        "# df.to_csv('./crawling_shinhan.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "후처리\n",
        "- attempt가 3이기 떄문에 중복으로 수집하는 것 같음. 중복처리 실시합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(df.columns)\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for col in df.columns:\n",
        "    df[col] = df[col].apply(lambda x: tuple(x) if isinstance(x, list) else (tuple(x.items()) if isinstance(x, dict) else x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.drop_duplicates(inplace=True)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('https://search.pstatic.net/common/?autoRotate=true&type=w560_sharpen&src=https%3A%2F%2Fvideo-phinf.pstatic.net%2F20240723_229%2F1721745070846WJY7f_JPEG%2FQLg3eZDGkE_03.jpg',\n",
              "  'https://pup-review-phinf.pstatic.net/MjAyNDA3MjNfMTIg/MDAxNzIxNzQ1MDY1NDg0.lemw_CM6_eOV2ToDKmOxfNpVbZ6T5lfCets6jfl5Vcog.SmDHuNlH0JOYnyLG3qInzqO953Y0LssVl8wa1xrjj9og.JPEG/049A7AF2-A517-405D-8F98-66E642FEBD37.jpeg?type=w560_sharpen',\n",
              "  'https://pup-review-phinf.pstatic.net/MjAyNDA3MjNfMjcx/MDAxNzIxNzQ1MDY1NjEy.qT_vqPnPzU49rVlqwvralCU17vFpnesu7nU8eUGMTMAg.CPkD5VZZqZaFBRNWOEuNBjkWZ8Hw_pTfgsLnZH9rEwcg.JPEG/ABA8D4D0-BB1B-4757-B3ED-321C1A8279E9.jpeg?type=w560_sharpen',\n",
              "  'https://search.pstatic.net/common/?autoRotate=true&type=w560_sharpen&src=https%3A%2F%2Fphinf.pstatic.net%2Ftvcast%2F20241001_199%2FxODei_1727774502019MCzhA_JPEG%2FPublishThumb_20241001_182124_604.jpg',\n",
              "  'https://search.pstatic.net/common/?autoRotate=true&type=w560_sharpen&src=http%3A%2F%2Fimage.nmv.naver.net%2Fblog_2024_09_15_2945%2F3Ceu1MtgvR_03.jpg')]"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 이미지 확인용\n",
        "# df[df['가게'] == '24시 뼈다귀탕 제주점']['사진'].tolist()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "이 부분에서 수정해서 위로 올렸음. 혹시 모르니 백업한 코드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from selenium import webdriver\n",
        "# from selenium.webdriver.common.by import By\n",
        "# from selenium.webdriver.common.keys import Keys\n",
        "# from selenium.webdriver.support.ui import WebDriverWait\n",
        "# from selenium.webdriver.support import expected_conditions as EC\n",
        "# from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
        "# import time\n",
        "# import pandas as pd\n",
        "# from selenium.webdriver import ActionChains\n",
        "\n",
        "\n",
        "# # Define the list of stores to be scraped\n",
        "# stores = search_cols_2\n",
        "# stores = ['1080칼국수','협재해녀의집','해송갈치 제주성산일출봉점','통큰돼지']\n",
        "# # Initialize webdriver options and webdriver\n",
        "# options = webdriver.ChromeOptions()\n",
        "# options.add_argument(\"--start-maximized\")\n",
        "# driver = webdriver.Chrome(options=options)\n",
        "\n",
        "# action = ActionChains(driver)\n",
        "# fail_to_crawling = []\n",
        "\n",
        "\n",
        "# ###################### 검색 키워드를 바탕으로 시작\n",
        "# results = []\n",
        "# for store in stores:\n",
        "#     ######################### 기본세팅\n",
        "#     # URL 입력\n",
        "#     keyword = store\n",
        "#     url = f'https://map.naver.com/p/search/{keyword}'\n",
        "#     driver.get(url)\n",
        "\n",
        "#     # 페이지 로드 \n",
        "#     try:\n",
        "#         WebDriverWait(driver, 3).until(\n",
        "#             lambda d: d.execute_script('return document.readyState') == 'complete'\n",
        "#         )\n",
        "#     except TimeoutException:\n",
        "#         print(f\"타임아웃 for {store}!\")\n",
        "#         continue\n",
        "\n",
        "#     ################ searchIframe 및 entryIframe에 따른 처리\n",
        "#     # 1. searchIframe일 경우 첫번째 가게 클릭하기\n",
        "#     try:\n",
        "#         search_iframe = WebDriverWait(driver, 4).until(\n",
        "#             EC.presence_of_element_located((By.XPATH, '//*[@id=\"searchIframe\"]'))\n",
        "#         )\n",
        "#         driver.switch_to.frame(search_iframe)\n",
        "        \n",
        "#         # Explicitly wait for the list container to load\n",
        "#         try:\n",
        "#             list_scroll_container = WebDriverWait(driver, 2).until(\n",
        "#             EC.presence_of_element_located((By.XPATH, '//*[@id=\"app-root\"]/div[@class=\"mFg6p\"]/div[@class=\"XUrfU\"]/div[@class=\"Ryr1F\"]'))\n",
        "#         )\n",
        "#             # 첫번째 가게항목\n",
        "#             # /ul/li[@class=\"VLTHu OW9LQ\"]/div[@class=\"qbGlu\"]/div[2]/a/div[@class=\"ApCpt\"]/div[@class=\"place_bluelink C6RjW\"]\n",
        "#             try : \n",
        "#                 first_result = list_scroll_container.find_element(By.XPATH, './ul/li[1]')\n",
        "#                 # print(f\"first_result : {first_result.get_attribute('innerHTML')}\")\n",
        "#             except : \n",
        "#                 first_result = list_scroll_container.find_element(By.CLASS_NAME, '/ul/li[@class=\"VLTHu OW9LQ\"]')\n",
        "#                 # print(f\"except first_result : {first_result.get_attribute('innerHTML')}\")\n",
        "\n",
        "#             # Try clicking using XPath first\n",
        "#             try:\n",
        "#                 link_button = first_result.find_element(By.XPATH, './div[1]/div[2]/a[1]/div/div/span')\n",
        "#                 # action chain을 이용해서 강제로 클릭하도록 설정\n",
        "#                 action.move_to_element(link_button).click().perform()\n",
        "#                 # print(f\"link_button : {link_button.get_attribute('innerHTML')}\")\n",
        "#                 # driver.execute_script(\"arguments[0].click();\", link_button)\n",
        "#                 ###### 디버깅파트\n",
        "#                 # print(f\"됐냐?\")\n",
        "#                 # current_url = driver.current_url\n",
        "#                 # print(f\"클릭 후 URL: {current_url}\")\n",
        "#                 # current_title = driver.title\n",
        "#                 # print(f\"클릭 후 페이지 타이틀: {current_title}\")\n",
        "#                 time.sleep(2)  # Wait for page transition\n",
        "#             except NoSuchElementException: \n",
        "#                 print(f\"링크버튼 어디감? xpath 대신 클래스 이름으로 시도\")\n",
        "#                 try:\n",
        "#                     # Fallback to class name\n",
        "#                     link_button = first_result.find_element(By.CLASS_NAME, 'place_bluelink')\n",
        "#                     action.move_to_element(link_button).click().perform()\n",
        "#                     time.sleep(3)  # Wait for page transition\n",
        "#                 except NoSuchElementException:\n",
        "#                     print(f\"링크버튼 어디감?\")\n",
        "#                     continue\n",
        "#         except TimeoutException:\n",
        "#             print(f\"Error while clicking first search result for {store}: Unable to locate list container.\")\n",
        "#             continue\n",
        "#     except TimeoutException:\n",
        "#         print(f\"Search iframe not found for {store}, attempting entry iframe.\")\n",
        "#         continue\n",
        "\n",
        "#     # 2. entryIframe일 경우 밑의 코드 진행 \n",
        "\n",
        "#     # iframe 세팅\n",
        "#     attempts = 0\n",
        "#     max_attempts = 3\n",
        "#     while attempts < max_attempts:\n",
        "#         try:\n",
        "#             driver.switch_to.default_content()\n",
        "#             iframe = WebDriverWait(driver, 5).until(\n",
        "#                 EC.presence_of_element_located((By.XPATH, '//*[@id=\"entryIframe\"]'))\n",
        "#             )\n",
        "#             print(f\"entryIframe 로드.\")\n",
        "#             driver.switch_to.frame(iframe)\n",
        "#             break\n",
        "#         except TimeoutException:\n",
        "#             attempts += 1\n",
        "#             time.sleep(1)  \n",
        "#             if attempts == max_attempts:\n",
        "#                 print(f\"Failed to load iframe after multiple attempts for {store}.\")\n",
        "#                 # 크롤링 실패한 부분은 리스트에 저장해서 다시 돌릴 수 있도록 지정\n",
        "#                 print(f\"crawling fatil : {store} to fail_to_crawling\")\n",
        "#                 fail_to_crawling.append(store)\n",
        "#                 continue\n",
        "\n",
        "#     # 로딩을 위해 스크롤링 진행\n",
        "#     SCROLL_PAUSE_TIME = 2\n",
        "#     last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
        "#     while True:\n",
        "#         driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "#         time.sleep(SCROLL_PAUSE_TIME)\n",
        "#         new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
        "#         if new_height == last_height:\n",
        "#             break\n",
        "#         last_height = new_height\n",
        "#     time.sleep(1)\n",
        "\n",
        "#     ###################### datalab 크롤링\n",
        "#     try:\n",
        "#         app_root = driver.find_element(By.XPATH, '//*[@id=\"app-root\"]')\n",
        "#         main_div = app_root.find_element(By.XPATH, './div/div/div[@role=\"main\"]')\n",
        "#         target_div = main_div.find_element(By.XPATH, './div[contains(@style, \"min-height\")]')\n",
        "#         datalab_section = target_div.find_element(By.XPATH, './div/div[9]')\n",
        "#         theme_keywords = datalab_section.find_element(By.CLASS_NAME, 'place_section_content')\n",
        "\n",
        "#         atmosphere_elements = theme_keywords.find_elements(By.XPATH, \".//ul/li[span[contains(text(), '분위기')]]/span[@class='sJgQj']/span\")\n",
        "#         popular_elements = theme_keywords.find_elements(By.XPATH, \".//ul/li[span[contains(text(), '인기토픽')]]/span[@class='sJgQj']/span\")\n",
        "#         purpose_elements = theme_keywords.find_elements(By.XPATH, \".//ul/li[span[contains(text(), '찾는목적')]]/span[@class='sJgQj']/span\")\n",
        "\n",
        "#         atmosphere = [elem.text for elem in atmosphere_elements]\n",
        "#         popular_topics = [elem.text for elem in popular_elements]\n",
        "#         purpose = [elem.text for elem in purpose_elements]\n",
        "\n",
        "#         result = {\n",
        "#             \"가게\": store,\n",
        "#             \"테마_분위기\": atmosphere,\n",
        "#             \"테마_인기토픽\": popular_topics,\n",
        "#             \"테마_찾는목적\": purpose\n",
        "#         }\n",
        "#         results.append(result)\n",
        "#     except Exception as e:\n",
        "#         print(f\"Error while extracting datalab information for {store}:\", e)\n",
        "    \n",
        "#     time.sleep(2)\n",
        "\n",
        "\n",
        "\n",
        "#     ############################## 리뷰로 넘어가서 진행하기\n",
        "#     try:\n",
        "#         # 리뷰버튼 클릭\n",
        "#         for k in range(1, 6) : \n",
        "#             try: \n",
        "#                 tab_button = driver.find_element(By.XPATH, f'//*[@id=\"app-root\"]/div/div/div/div[4]/div/div/div/div/a[{k}]')\n",
        "#                 span_text = tab_button.find_element(By.XPATH, './span').text\n",
        "#                 if span_text == '리뷰':\n",
        "#                     review_button = tab_button\n",
        "#                     break \n",
        "#             except Exception as e:\n",
        "#                 continue \n",
        "#         if review_button: \n",
        "#             review_button.click() \n",
        "#             # 리뷰 탭 로딩 확인\n",
        "#             try:\n",
        "#                 WebDriverWait(driver, 5).until(\n",
        "#                     EC.presence_of_element_located((By.XPATH, '//*[@id=\"app-root\"]/div/div/div/div[6]'))\n",
        "#                 )\n",
        "#                 print(f\"{store}: 리뷰 페이지 로드 성공\")\n",
        "#             except TimeoutException:\n",
        "#                 print(f\"{store}: 리뷰 페이지 로드 실패, 사진 수집으로 넘어가지 않음\")\n",
        "#                 continue\n",
        "\n",
        "#         # iframe 로딩을 위해 스크롤링 진행\n",
        "#         last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
        "#         while True:\n",
        "#             driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "#             time.sleep(SCROLL_PAUSE_TIME)\n",
        "#             new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
        "#             if new_height == last_height:\n",
        "#                 break\n",
        "#             last_height = new_height\n",
        "#         time.sleep(2)\n",
        "\n",
        "#         # 리뷰 정보를 수집할 준비\n",
        "        \n",
        "#         ############################## 리뷰 정보 수집\n",
        "#         try:\n",
        "#             review_box = driver.find_element(By.XPATH, '//*[@id=\"app-root\"]/div/div/div/div[6]/div[3]/div[3]/div[1]')\n",
        "#         except:\n",
        "#             review_box = driver.find_element(By.CLASS_NAME, 'place_section_content')\n",
        "\n",
        "#         try:\n",
        "#             tag_filters = review_box.find_element(By.XPATH, '//*[@id=\"_tag_filters\"]/div/div')\n",
        "#         except:\n",
        "#             tag_filters = review_box.find_element(By.CLASS_NAME, 'mWnvl')\n",
        "\n",
        "#         menu_features = {}\n",
        "#         feature_items = {}\n",
        "#         for n in range(1, 3):\n",
        "#             try:\n",
        "#                 div_element = tag_filters.find_element(By.XPATH, f'//*[@id=\"_tag_filters\"]/div/div[{n}]')\n",
        "#             except:\n",
        "#                 div_element = tag_filters.find_element(By.XPATH, f'.//div[{n}]')\n",
        "\n",
        "#             if n == 1:\n",
        "#                 div_class = \"JWiV0 eZMAS xcTvu\"  # 메뉴\n",
        "#             elif n == 2:\n",
        "#                 div_class = \"JWiV0 khWUF eZMAS xcTvu\"  # 특징\n",
        "\n",
        "#             try:\n",
        "#                 menu_items = div_element.find_elements(By.XPATH, './/a')\n",
        "#                 for item in menu_items:\n",
        "#                     span_1 = item.find_element(By.XPATH, './span[1]').text\n",
        "#                     span_2 = item.find_element(By.XPATH, './span[2]').text\n",
        "#                     if n == 1:\n",
        "#                         menu_features[span_1] = span_2\n",
        "#                     elif n == 2:\n",
        "#                         feature_items[span_1] = span_2\n",
        "#             except Exception as e:\n",
        "#                 print(f\"Error while extracting menu/features for {store}, div {n}:\", e)\n",
        "\n",
        "#         # Add the menu and features data to the result\n",
        "#         result[\"메뉴\"] = menu_features\n",
        "#         result[\"특징\"] = feature_items\n",
        "#     except Exception as e:\n",
        "#         print(f\"Error while navigating to reviews for {store}:\", e)\n",
        "    \n",
        "#     time.sleep(1)\n",
        "    \n",
        "#     ############################## 사진으로 넘어가서 진행하기\n",
        "#     try:\n",
        "#         # 사진 버튼 클릭\n",
        "#         photo_button = None\n",
        "#         for k in range(1, 6):\n",
        "#             try:\n",
        "#                 tab_button = driver.find_element(By.XPATH, f'//*[@id=\"app-root\"]/div/div/div/div[4]/div/div/div/div/a[{k}]')\n",
        "#                 span_text = tab_button.find_element(By.XPATH, './span').text\n",
        "#                 if span_text == '사진':\n",
        "#                     photo_button = tab_button\n",
        "#                     break\n",
        "#             except Exception as e:\n",
        "#                 continue\n",
        "\n",
        "#         if photo_button:\n",
        "#             photo_button.click()\n",
        "#         else:\n",
        "#             print(f\" 사진 버튼 없음 : {store}.\")\n",
        "#             continue\n",
        "        \n",
        "#         # 스크롤 세 번 진행\n",
        "#         for _ in range(3):\n",
        "#             driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "#         time.sleep(1)\n",
        "        \n",
        "#         # 사진 정보 수집\n",
        "#         pic_tmp = []\n",
        "#         try:\n",
        "#             app_root = driver.find_element(By.XPATH, '//*[@id=\"app-root\"]')\n",
        "#             main_div = app_root.find_element(By.XPATH, './div/div')\n",
        "#             role_main_div = main_div.find_element(By.XPATH, './div[@role=\"main\"]')\n",
        "#             target_div = role_main_div.find_element(By.XPATH, './div[contains(@style, \"min-height\")]')\n",
        "#         except Exception as e:\n",
        "#             print(f\"위치 못찾음 : {store}:\", e)\n",
        "#             continue\n",
        "\n",
        "#         try:\n",
        "#             photo_section = target_div.find_element(By.XPATH, './div[contains(@class, \"place_section\")]')\n",
        "#             # print(f'photo_section found: {photo_section}')\n",
        "#         except:\n",
        "#             try:\n",
        "#                 photo_section = target_div.find_element(By.CLASS_NAME, 'place_section no_margin')\n",
        "#                 # print(f'photo_section (alternative) found: {photo_section}')\n",
        "#             except Exception as e:\n",
        "#                 print(f\"photo section 못찾음 {store}: {e}\")\n",
        "#                 continue\n",
        "#         try:\n",
        "#             photo_content = WebDriverWait(driver, 1).until(\n",
        "#                 EC.presence_of_element_located((By.CLASS_NAME, 'place_section_content'))\n",
        "#             )\n",
        "#             # print(f'photo_content found: {photo_content}')\n",
        "#         except Exception as e:\n",
        "#             print(f'photo_content 못찾음 {store}: {e}')\n",
        "#             continue\n",
        "\n",
        "#         # print(f\"photo_content : {photo_content}\")\n",
        "#         for n in range(1, 11):\n",
        "#             try:\n",
        "#                 photo_div = photo_content.find_element(By.XPATH, f'./div/div/div[{n}]/a')\n",
        "#                 img_element = photo_div.find_element(By.XPATH, './img')\n",
        "#                 img_src = img_element.get_attribute('src')\n",
        "#                 pic_tmp.append(img_src)\n",
        "#             except Exception as e:\n",
        "#                 print(f\"이미지 추출 오류 {n} for {store}: {e}\")\n",
        "\n",
        "#         result[\"사진\"] = pic_tmp\n",
        "#     except Exception as e:\n",
        "#         print(f\"Error while navigating to photos for {store}:\", e)\n",
        "\n",
        "#     # Append the result for each store\n",
        "#     results.append(result)\n",
        "\n",
        "# ################ Close the browser\n",
        "# # driver.quit()\n",
        "\n",
        "# ################### 크롤링 최종결과를 df에 저장\n",
        "# df = pd.DataFrame(results)\n",
        "# ################## 원본데이터에 입력\n",
        "# # df = pd.merge(df, shinhan, on='가게명', how='outer')\n",
        "\n",
        "# ################### 통합된 데이터 저장\n",
        "# # df.to_csv('./crawling_shinhan.csv', index=False)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
